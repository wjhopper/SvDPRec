---
title: "2HT Modeling"
author: "William Hopper"
date: "`r format(Sys.Date(), '%b %d, %Y')`"
output:
  html_document:
    toc: true
    toc_depth: 3
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, fig.align = "center")
# library(gamlss.dist)
library(rprojroot)
library(kableExtra)
library(optimx)
library(foreach)
library(tidyr)
library(ggplot2)
library(dplyr)
root_dir <- rprojroot::is_rstudio_project$find_file()
```

```{css}
.main-container {
    max-width: 1200px;
}
img {
  padding-top: 10px;
}
```

```{r load_data}
load(file.path(root_dir, "data", "SvDPRec.Rdata"))
test <- select(test, -list)
```

```{r cell_counts, cache=TRUE}
delayed_counts_by_sub_bias <- filter(test, !is.na(type)) %>%
  select(-starts_with("speeded")) %>%
  rename(correct = delayed_correct) %>%
  count(subject, strength, pOld, correct) %>%
  complete(subject, strength, pOld, correct,
           fill = list(n=0)) %>%
  unite(col = "resp_type", strength, correct) %>%
  spread(resp_type, n) %>%
  rename(FA = L_FALSE, CR = L_TRUE,
         M_S = S_FALSE, H_S = S_TRUE,
         M_W = W_FALSE, H_W = W_TRUE) %>%
  mutate(FA_N = FA + CR,
         S_N = M_S + H_S,
         W_N = M_W + H_W) %>%
  select(subject, pOld, FA, CR, FA_N, H_S, M_S, S_N, H_W, M_W, W_N)

speeded_RT_choice_quantiles <- filter(test, !is.na(type)) %>%
  filter(speeded_RT > 200) %>%
  mutate(speeded_RT = speeded_RT/1000) %>%
  group_by(subject, strength, speeded_correct) %>%
  summarise(quintiles = list(
              data.frame(quantile = c("10%", "30%", "50%", "70%", "90%", "100%"),
                         value = quantile(speeded_RT, c(.1, .3, .5, .7, .9, 1)),
                         bin_counts = floor(n() * c(.1, .2, .2, .2, .2, .1)),
                         stringsAsFactors = FALSE)
              )) %>%
  ungroup() %>%
  unnest()

speeded_acc <- filter(test, !is.na(type)) %>%
  group_by(subject, strength) %>%
  summarise(acc = mean(speeded_correct))
```


```{r discrete_race_exgaussians, cache=TRUE}
## mu, sigma & nu should be vectors of length 2
## First element should be parameter for detect distribution
## Second element should be parameter for guess distribution

## Weight is also vector of length
## First element is probability of detection being available
## Second element is probability of guessing correctly
## These are independent probabilities, need not sum to 1
dcRT <- function(x, mu, sigma, nu, weights) {
  
  pDetect <- weights[1]
  pGuess_correct <- weights[2]
  
  p_detect_process_unfinished <- gamlss.dist::pexGAUS(x, mu[1], sigma[1], nu[1], lower.tail = FALSE)
  p_guess_process_unfinished <- gamlss.dist::pexGAUS(x, mu[2], sigma[2], nu[2], lower.tail = FALSE)
  
  detect_RT_density <- gamlss.dist::dexGAUS(x, mu[1], sigma[1], nu[1])
  guess_RT_density <- gamlss.dist::dexGAUS(x, mu[2], sigma[2], nu[2])
  
  
  correct_RT_density <- 
    # Detect RT's, weighted by probability you can detect and haven't given up & guessed yet
    pDetect * p_guess_process_unfinished * detect_RT_density + 
    # Guess RT's, weighted by probability you could detect but give up "early" and guess correctly
    pDetect * p_detect_process_unfinished * pGuess_correct * guess_RT_density + 
    # uess RT's, weighted by probability you can not detect but guess correctly
    (1-pDetect) * pGuess_correct * guess_RT_density
  
  return(correct_RT_density)
}

## mu, sigma & nu should be vectors of length 2
## Nu is mean of exponential process (also denoted as tao sometimes)
## First element should be parameter for detect distribution
## Second element should be parameter for guess distribution

## Weight is also vector of length
## First element is probability of detection being available
## Second element is probability of guessing *incorrectly*
## These are independent probabilities, need not sum to 1

deRT <- function(x, mu, sigma, nu, weights) {
  ## mu, sigma & nu should be vectors of length 2
  pDetect <- weights[1]
  pGuess_incorrect <- 1-weights[2]
  
  p_detect_process_unfinished <- gamlss.dist::pexGAUS(x, mu[1], sigma[1], nu[1], lower.tail = FALSE)
  guess_RT_density <- gamlss.dist::dexGAUS(x, mu[2], sigma[2], nu[2])
  
  incorrect_RT_density <- # sum of:
    # Guess RT's, weighted by probability you could detect but give up "early" and guess incorrectly 
    pDetect * p_detect_process_unfinished * pGuess_incorrect * guess_RT_density +
    # Guess RT's, weighted by probability detection is not availble and you guess incorrectly
    (1-pDetect) * pGuess_incorrect * guess_RT_density
  
  return(incorrect_RT_density)
  }
```

```{r discrete_race_objective_functions, cache=TRUE}

DR_predictions <- function(parameters, data) {
  data$predicted_p <- numeric(nrow(data))

  for (strength in unique(data$strength)) {

    condition_index <- data$strength==strength
    
    if (strength == "L") {
      detect_correctly <- parameters['dNew.L']
      guess_correctly <- 1 - parameters['gOld']
    } else {
      detect_correctly <- parameters[paste0('dOld.', strength)]
      guess_correctly <- parameters['gOld']
    }

    for (acc in unique(data$speeded_correct)) {

      if (acc) {
        density_fn = dcRT
      } else {
        density_fn = deRT
      }

      index_vector <- condition_index & data$speeded_correct == acc 
      cutpoints <- c(0, data$value[index_vector])
      cutpoints[length(cutpoints)] <- Inf

      p <- numeric(length(cutpoints)-1)
      for (bin_number in 1:length(p)) {

        x <- integrate(density_fn, cutpoints[bin_number], cutpoints[bin_number+1],
                       mu = parameters[c("mu.d","mu.g")],
                       sigma = parameters[c("sigma","sigma")],
                       nu = parameters[c("nu","nu")],
                       weights = c(detect_correctly, guess_correctly)
                       )
        p[bin_number] <- x$value
      }

      data$predicted_p[index_vector] <- p
    }
  }

  return(data)
}

DR_quantiles <- function(parameters, data) {
  
  data$predicted_qValue <- numeric(nrow(data))

  for (strength in unique(data$strength)) {

    condition_index <- data$strength==strength
    
    if (strength == "L") {
      detect_correctly <- parameters['dNew.L']
      guess_correctly <- 1 - parameters['gOld']
    } else {
      detect_correctly <- parameters[paste0('dOld.', strength)]
      guess_correctly <- parameters['gOld']
    }

    n_samples <- 1000
    n_detect_trials <- rbinom(1, size = n_samples, p = detect_correctly)
    detect_RTs <- c(gamlss.dist::rexGAUS(n_detect_trials,
                                         mu = parameters["mu.d"],
                                         sigma = parameters["sigma"],
                                         nu = parameters["nu"]),
                    rep(Inf, n_samples - n_detect_trials)
                    )

    guess_RTs <- gamlss.dist::rexGAUS(n_samples,
                                      mu = parameters["mu.g"],
                                      sigma = parameters["sigma"],
                                      nu = parameters["nu"]
                                      )

    RTs <- pmin(detect_RTs, guess_RTs)
    detect_wins <- detect_RTs == RTs
    accuracy <- logical(n_samples)
    accuracy[detect_wins] <- TRUE
    accuracy[!detect_wins] <- as.logical(rbinom(sum(!detect_wins), 1, guess_correctly))

    data$predicted_qValue[data$speeded_correct] <-
      quantile(RTs[accuracy], c(.1, .3, .5, .7, .9, 1))
    
    data$predicted_qValue[!data$speeded_correct] <-
      quantile(RTs[!accuracy], c(.1, .3, .5, .7, .9, 1))
  }

  return(data)
}

DR_LL <- function(parameters, data, fixed=NULL){

  parameters <- c(parameters, fixed)
  data$predicted_p <- numeric(nrow(data))
  log_likelihood <- 0

  for (strength in unique(data$strength)) {

    condition_index <- data$strength==strength
    
    if (strength == "L") {
      detect_correctly <- parameters['dNew.L']
      guess_correctly <- 1 - parameters['gOld']
    } else {
      detect_correctly <- parameters[paste0('dOld.', strength)]
      guess_correctly <- parameters['gOld']
    }

    for (acc in unique(data$speeded_correct)) {

      if (acc) {
        density_fn = dcRT
      } else {
        density_fn = deRT
      }

      index_vector <- condition_index & data$speeded_correct == acc 
      cutpoints <- c(0, data$value[index_vector])
      cutpoints[length(cutpoints)] <- Inf

      p <- numeric(length(cutpoints)-1)
      for (bin_number in 1:length(p)) {

        x <- integrate(density_fn, cutpoints[bin_number], cutpoints[bin_number+1],
                       mu = parameters[c("mu.d","mu.g")],
                       sigma = parameters[c("sigma","sigma")],
                       nu = parameters[c("nu","nu")],
                       weights = c(detect_correctly, guess_correctly)
                       )
        p[bin_number] <- x$value
      }

      data$predicted_p[index_vector] <- p
    }

    condition_index <- data$strength==strength
    bin_counts <- data$bin_counts[condition_index]
    log_likelihood <- log_likelihood + dmultinom(x = bin_counts, size = sum(bin_counts),
                                                 prob = data$predicted_p[condition_index],
                                                 log = TRUE)
  }

  return(-log_likelihood)
}
```


```{r 2HT, cache=TRUE}
twoHT_LL <- function(detect, guess, counts) {
  FA <- (1-detect['dNew.L'])*guess
  HR_W <- detect['dOld.W'] + (1-detect['dOld.W'])*guess 
  HR_S <- detect['dOld.S'] + (1-detect['dOld.S'])*guess

  LL <- c(dbinom(counts$H_S, size = counts$S_N, prob = HR_S, log=TRUE),
          dbinom(counts$H_W, size = counts$W_N, prob = HR_W, log=TRUE),
          dbinom(counts$FA, size = counts$FA_N, prob = FA, log=TRUE)
          )
  return(-sum(LL))
}
```

```{r fit, cache=TRUE, dependson=c("discrete_race_exgaussians", "discrete_race_objective_functions", "2HT")}
cl <- parallel::makeCluster(parallel::detectCores(),
                            outfile = "",
                            methods = FALSE)

doParallel::registerDoParallel(cl)

twoHT_DR_LL_sum <- function(theta, ...) {

  trailing <- list(...) 

  twoHT_negLL <- twoHT_LL(detect=theta[c("dNew.L", "dOld.W", "dOld.S")],
                          guess=theta[c("gC", "gN", "gL")], #this order matters
                          counts = trailing$counts)
  
  DR_negLL <- DR_LL(theta[c("dNew.L", "dOld.W", "dOld.S", "gOld",
                            "mu.d", "mu.g", "sigma", "nu")],
                    data = trailing$data)
  
  negLL <- twoHT_negLL + DR_negLL
  if (is.infinite(negLL) || is.nan(negLL)) {
    negLL <- .Machine$double.xmax
  }
  return(negLL)
}

subjectwise_datalist <- Map(
  function(x,y) { list("speeded" = x,"biased" = y)},
  split(speeded_RT_choice_quantiles, speeded_RT_choice_quantiles$subject),
  split(delayed_counts_by_sub_bias, delayed_counts_by_sub_bias$subject)
  )

fits <- foreach(sub = subjectwise_datalist,
                   .packages = c("rtdists","optimx")) %dopar% {

  theta <- c("dNew.L" = .5, "dOld.W" = .5, "dOld.S"=.75, "gOld"=.5,
             "mu.d" = .5, "mu.g" = .75, "sigma" = .25, "nu" = .25,
             "gC" = .5, "gN" = .5, "gL" = .5
             )
    fit <- optimx(theta,
                  fn = twoHT_DR_LL_sum,
                  method = "nlminb",
                  itnmax = 3000,
                  lower = c(.01, .01, .01, .01, .01, .01, .01, .01, .01, .01, .01),
                  upper = c(1,   1,   1,   1,   2,   2,   .5,  .5,  1,   1,   1),
                  control = list(kkt=FALSE),
                  data = sub$speeded,
                  counts = sub$biased[c("FA", "FA_N", "H_W", "W_N", "H_S", "S_N")]
                  )

    fit$subject <- sub$speeded$subject[1]
    fit
  }

parallel::stopCluster(cl)

fits <- select(bind_rows(fits), subject, dNew.L:convcode)

GOF <- select(fits, subject, value:convcode) %>%
  rename(`-LL` = value) %>%
  mutate(deviance = 2*`-LL`)

twoHT_params <- select(fits, subject, dNew.L, dOld.W, dOld.S, gC, gN, gL)

DR_params <- select(fits, subject, dNew.L, dOld.W, dOld.S, gOld, mu.d, mu.g, sigma, nu)
```

```{r speeded_RT_predictions, cache=TRUE, dependson="fit"}
DR_bin_probabilities <- Map(DR_predictions,
                        lapply(split(DR_params, DR_params$subject), function(x) unlist(x[2:9])),
                        lapply(subjectwise_datalist, `[[`, "speeded")
                        ) %>%
  bind_rows() %>%
  group_by(subject, strength, speeded_correct) %>%
  mutate(observed_p = bin_counts/sum(bin_counts)) %>%
  group_by(subject, strength) %>%
  mutate(observed_p = observed_p*c(rep(sum(bin_counts[!speeded_correct])/sum(bin_counts), 6),
                                   rep(sum(bin_counts[speeded_correct])/sum(bin_counts), 6))
         ) %>%
  ungroup()

DR_acc <- group_by(DR_bin_probabilities,
                   subject, strength, speeded_correct) %>%
  summarise_at(c("observed_p","predicted_p"), sum) %>%
  ungroup() %>%
  gather("type", "p", observed_p, predicted_p) %>%
  mutate(type = sub("_p", "", type)) %>%
  arrange(subject, strength, speeded_correct)

DR_pred_quantiles <- Map(DR_quantiles,
                    lapply(split(DR_params, DR_params$subject), function(x) unlist(x[2:9])),
                    lapply(subjectwise_datalist, `[[`, "speeded")
                    ) %>%
  bind_rows() %>%
  select(-bin_counts) %>%
  rename(observed=value) %>%
  gather("type", "value", observed, predicted_qValue) %>%
  mutate(type = sub("_.", "", type),
         type = sub("Value", "", type, fixed=TRUE))

```

```{r delayed_acc_predictions, cache=TRUE, dependson="fit"}
FAR_points <- seq(0, 1, .01)
twoHT_ROC <- rowwise(twoHT_params) %>%
  mutate(twoHT = list(
    data.frame(FAR = rep(FAR_points, 2),
               strength = rep(c("W", "S"), each = length(FAR_points)),
               HR = c( ((1-dOld.W)/(1-dNew.L)*FAR_points) + dOld.W,
                       ((1-dOld.S)/(1-dNew.L)*FAR_points) + dOld.S
                      ),
               type = "pred")
    )) %>%
  select(subject, twoHT) %>%
  unnest()

ROC_by_sub <- mutate(delayed_counts_by_sub_bias,
         FAR = FA / FA_N,
         HR_W = H_W / W_N,
         HR_S = H_S / S_N
         ) %>%
  select(subject, pOld, FAR, HR_W, HR_S) %>%
  gather(key = "strength", value = "HR", HR_W, HR_S) %>%
  arrange(subject, desc(strength)) %>%
  mutate(strength = sub("HR_", "", strength, fixed=TRUE))
```

```{r g2, cache=TRUE, dependson="fit"}
speeded_RT_deviance <- speeded_RT_choice_quantiles %>%
  group_by(subject, strength) %>%
  mutate(observed_p = bin_counts/sum(bin_counts)) %>%
  summarise(LL = dmultinom(bin_counts, sum(bin_counts), observed_p, log=TRUE)) %>%
  group_by(subject) %>%
  summarise(null_deviance = -2*sum(LL))

delayed_acc_deviance <- mutate(delayed_counts_by_sub_bias,
         FA_LL = dbinom(FA, FA_N, FA/FA_N, log=TRUE),
         HW_LL = dbinom(H_W, W_N, H_W/W_N, log=TRUE),
         HS_LL = dbinom(H_S, S_N, H_S/S_N, log=TRUE),
         LL = FA_LL + HW_LL + HS_LL) %>%
  select(subject, pOld, LL) %>%
  group_by(subject) %>%
  summarise(null_deviance = -2*sum(LL))

null_deviance <- left_join(speeded_RT_deviance, delayed_acc_deviance,
                           by="subject",suffix=c(".RT",".acc")) %>%
  transmute(subject,
            null_deviance = null_deviance.RT + null_deviance.acc)

data_df <- 9 + 33 # 9 Hit/FA rates, 33 free RT bins
model_df <- 11 # 6 2HT params, 8 discrete race params - 3 shared (the detect parameters)

g2 <- left_join(select(GOF, subject, deviance),
                null_deviance,
                by = "subject") %>% 
  mutate(G2 = deviance - null_deviance,
         p = pchisq(G2, df = data_df - model_df, lower.tail = FALSE)
         )

GOF <- left_join(select(GOF, -deviance),
                 select(g2, subject, G2, p),
                 by="subject")
```

```{r ROC, cache=TRUE, dependson="fit", fig.height=12, fig.width=9}
ggplot(twoHT_ROC,
       aes(x=FAR, y=HR, color=strength)) +
  geom_line(size=.8) +
  geom_point(aes(shape = factor(pOld)),
             data=ROC_by_sub) +
  facet_wrap(~ subject,
             labeller = labeller(subject = label_both,
                                 .multi_line = FALSE),
             ncol=4) +
  scale_x_continuous("False Alarm Rate", limits = c(0,1),
                     labels = c(0,0.25, 0.5, 0.75, 1)) +
  scale_y_continuous("Hit Rate", limits = c(0,1)) +
  scale_color_manual("Strength", values = c("#2470b7", "#b70e1c")) +
  scale_shape_discrete("pOld") +
  guides(colour = guide_legend(override.aes = list(size = 4)),
         shape = guide_legend(override.aes = list(size = 4))) +
  coord_fixed() +
  ggtitle("Predicted ROC for delayed judgments") +
  theme_bw(base_size = 13) +
  theme(legend.position = c(.75, .1),
        legend.box = "horizontal")
```

```{r DR_plots, cache=TRUE, dependson="fit", fig.width=9, fig.align="center", results="asis"}

formatted_names <- c("Model",
                     "D<sub>L</sub>", "D<sub>W</sub>", "D<sub>S</sub>", "G<sub>old</sub>",
                     "\u03BC<sub>D</sub>", "\u03BC<sub>G</sub>", "&sigma;", "τ")

for (s in unique(fits$subject)) {
  
  cat(sprintf("<h3>Subject %s</h3>", s))
  
  subject_params <- filter(DR_params, subject == s)
  kable(subject_params,
        digits = 3,
        col.names = formatted_names,
        escape = FALSE) %>%
    kableExtra::kable_styling(full_width = FALSE, position = "float_left") %>%
    print()

    kable(filter(GOF, subject == s), digits = 3) %>%
    kableExtra::kable_styling(full_width = FALSE, position = "float_right") %>%
    print()
    
  acc_plot <-
    ggplot(filter(DR_acc, subject == s, speeded_correct),
          aes(x=strength, y=p, shape=type, color=strength)) +
    geom_point(size=2,stroke=2) +
    scale_shape_manual("",
                       values = c(16,4),
                       breaks = c("observed","predicted")
                       ) +
    scale_color_discrete(labels = c("L" = "Lure",
                                    "W" = "Weak\nTarget",
                                    "S" = "Strong\nTarget")
                         ) +
    scale_y_continuous("Percent Correct", limits = c(0, 1)) +
    scale_x_discrete(labels = c("L" = "Lure",
                                "W" = "Weak\nTarget",
                                "S" = "Strong\nTarget"),
                     expand = c(0, .2)) +
    theme(legend.key.height = unit(9, 'mm'))
  
  quantile_plot <- 
    ggplot(filter(DR_pred_quantiles, subject == s, quantile != "100%"),
           aes(x=quantile, y=value, shape=type, color=strength)) +
    geom_point(size=1.5) +
    geom_line(aes(group=type)) +
    facet_grid(speeded_correct ~ strength,
               labeller = labeller(speeded_correct = as_labeller(
                                    c("TRUE" = "Correct",
                                      "FALSE" = "Error")
                                    ),
                                    strength = as_labeller(
                                      c("L" = "Lure",
                                        "S" = "Strong Target",
                                        "W" = "Weak Target")
                                    )
                                   )
               ) +
    scale_shape_manual(values=c(16,4),
                   breaks=c("observed","predicted")
                   ) +
    scale_y_continuous("RT Quantile Value (s.)") +
    guides(color=FALSE, shape=FALSE)
  
  gridExtra::grid.arrange(acc_plot, quantile_plot, nrow=1,
                          widths=c(.35, .65))
}
```
