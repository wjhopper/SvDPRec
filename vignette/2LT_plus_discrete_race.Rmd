---
title: "Discrete Race  + Two Low-Threshold"
author: "William Hopper"
date: "`r format(Sys.Date(), '%b %d, %Y')`"
output:
  html_document:
    toc: true
    toc_depth: 3
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, fig.align = "center", cache=TRUE)
options(knitr.kable.NA = '-')
library(iterators)
library(gamlss.dist)
library(rprojroot)
library(kableExtra)
library(optimx)
library(foreach)
library(tidyr)
library(ggplot2)
library(dplyr)
root_dir <- rprojroot::is_rstudio_project$find_file()
```

```{css css}
.main-container{
  max-width: 1200px;
}

#individual-subjects img{
  padding-bottom: 100px;
}
```

```{r load_data}
load(file.path(root_dir, "data", "SvDPRec.Rdata"))
test <- select(test, -list)
```

```{r cell_counts, dependson="load_data"}
delayed_counts_by_sub_bias <- filter(test, !is.na(type)) %>%
  select(-starts_with("speeded")) %>%
  rename(correct = delayed_correct) %>%
  count(subject, strength, pOld, correct) %>%
  complete(subject, strength, pOld, correct,
           fill = list(n=0)) %>%
  unite(col = "resp_type", strength, correct) %>%
  spread(resp_type, n) %>%
  rename(FA = L_FALSE, CR = L_TRUE,
         M_S = S_FALSE, H_S = S_TRUE,
         M_W = W_FALSE, H_W = W_TRUE) %>%
  mutate(L_N = FA + CR,
         S_N = M_S + H_S,
         W_N = M_W + H_W) %>%
  select(subject, pOld, FA, CR, L_N, H_S, M_S, S_N, H_W, M_W, W_N)

speeded_RT_choice_quantiles <- filter(test, !is.na(type)) %>%
  filter(speeded_RT > 200) %>%
  mutate(speeded_RT = speeded_RT/1000) %>%
  group_by(subject, strength, speeded_correct) %>%
  summarise(quintiles = list(
              data.frame(quantile = c("10%", "30%", "50%", "70%", "90%", "100%"),
                         value = quantile(speeded_RT, c(.1, .3, .5, .7, .9, 1)),
                         bin_counts = floor(n() * c(.1, .2, .2, .2, .2, .1)),
                         stringsAsFactors = FALSE)
              )) %>%
  ungroup() %>%
  unnest()

speeded_acc <- filter(test, !is.na(type)) %>%
  group_by(subject, strength) %>%
  summarise(acc = mean(speeded_correct))

obs_ROC_data <- mutate(delayed_counts_by_sub_bias,
                       FAR = FA/L_N,
                       HR_W = H_W/W_N,
                       HR_S = H_S/S_N,
                       pOld = sprintf("%2.0f%%", pOld*100)) %>%
  select(subject, pOld, FAR, HR_W, HR_S) %>%
  gather(key="strength", value="HR", HR_W, HR_S) %>%
  mutate(strength = sub("HR_", "", strength)) %>%
  select(subject, pOld, strength, FAR, HR)

obs_avg_ROC_data <- group_by(obs_ROC_data, pOld, strength) %>%
  summarise_at(.vars = c("FAR", "HR"), .funs = "mean") %>%
  ungroup()
```

```{r discrete_race_exgaussians}
## mu, sigma & nu should be vectors of length 2
## First element should be parameter for detect distribution
## Second element should be parameter for guess distribution

## Weight is also vector of length
## First element is probability of detection being available
## Second element is probability of guessing correctly
## These are independent probabilities, need not sum to 1
dcRT <- function(x, mu, sigma, nu, weights) {
  
  pDetect_Old <- weights[1]
  pFail <- weights[2]
  pDetect_New <- weights[3]
  pGuess_Correct <- weights[4:6]
  
  p_DO_process_unfinished <- gamlss.dist::pexGAUS(x, mu[1], sigma[1], nu[1], lower.tail = FALSE)
  p_guess_process_unfinished <- gamlss.dist::pexGAUS(x, mu[2], sigma[2], nu[2], lower.tail = FALSE)
  p_DN_process_unfinished <- gamlss.dist::pexGAUS(x, mu[3], sigma[3], nu[3], lower.tail = FALSE)
  
  DO_RT_density <- gamlss.dist::dexGAUS(x, mu[1], sigma[1], nu[1])
  guess_RT_density <- gamlss.dist::dexGAUS(x, mu[2], sigma[2], nu[2])
  DN_RT_density <- gamlss.dist::dexGAUS(x, mu[3], sigma[3], nu[3])
  
  # Detect Old Pathway
  DO <- pDetect_Old * p_guess_process_unfinished * DO_RT_density * pGuess_Correct[3]
  # Detect New Pathway
  DN <- pDetect_New * p_guess_process_unfinished * DN_RT_density * pGuess_Correct[1]
  # Fail to Detect pathway, detection unavailable
  FD <- pFail * guess_RT_density * pGuess_Correct[2]
  # Fail to Detect pathway, guessing beats detect old
  FD_beats_DO <- pDetect_Old * p_DO_process_unfinished * guess_RT_density * pGuess_Correct[2]
  # Fail to Detect pathway, guessing beats detect new
  FD_beats_DN <- pDetect_New * p_DN_process_unfinished * guess_RT_density * pGuess_Correct[2]
  
  correct_RT_density <- DO + DN + FD + FD_beats_DO + FD_beats_DN
  return(correct_RT_density)
}
## mu, sigma & nu should be vectors of length 2
## Nu is mean of exponential process (also denoted as tao sometimes)
## First element should be parameter for detect distribution
## Second element should be parameter for guess distribution

## Weight is also vector of length
## First element is probability of detection being available
## Second element is probability of guessing *incorrectly*
## These are independent probabilities, need not sum to 1

deRT <- function(x, mu, sigma, nu, weights) {
  weights[4:6] <- 1 - weights[4:6]
  incorrect_RT_density <- dcRT(x, mu, sigma, nu, weights)
  return(incorrect_RT_density)
}
```

```{r objective_functions}

softmax <- function(x) {
  return(exp(x)/sum(exp(x)))
}

ilogit <- function(x, max=1) {
  return(max/(1+exp(-x)))
}

calculate_RO_parameters <- function(b, reverse=FALSE) {

  # Compute response probabilities from each detect state based on bias parameter
  if (b > 2 || b < -1) {
    stop("Bias parameter must lie within [-1, 2]")
  }
  
  param_names <- names(b)
  names(b) <- sub("b_", "", param_names)
  
  RO_DN <- abs(pmin(b, 0))
  RO_FD <- pmax(pmin(1-b, 1), 0)
  RO_DO <-  2 - pmax(b, 1)
  theta <- c("RO_DN"=RO_DN, "RO_FD"=RO_FD, "RO_DO"=RO_DO)
  
  if (reverse) {
    theta <- 1-theta
  }
  return(theta)
}


parameter_scaling <- function(theta) {

  # Compute response probabilities from each detect state based on bias parameter
  bias_param_ind <- startsWith(names(theta), "b")
  rescaled_bias_params <- -1 + ilogit(x = theta[bias_param_ind], max=3)
  theta[bias_param_ind] <- rescaled_bias_params
  RO_params <- calculate_RO_parameters(rescaled_bias_params)
  
  # Add new vector elements for the parameters that are computed based on existing ones.
  theta <- c(theta, RO_params, "DN_L"=NA_real_, "DN_W"=NA_real_, "DN_S"=NA_real_)

  # Convert detect paramters from log-odds scale to probability scale
  theta[c("DO_L", "FD_L", "DN_L")] <- softmax(c(theta[c("DO_L", "FD_L")], 0))
  theta[c("DO_W", "FD_W", "DN_W")] <- softmax(c(theta[c("DO_W", "FD_W")], 0))
  theta[c("DO_S", "FD_S", "DN_S")] <- softmax(c(theta[c("DO_S", "FD_S")], 0))

  return(theta)
}


pDR <- function(rt, correct, DO, FD, b, mu.do, mu.g, mu.dn, sigma, nu, reverse=FALSE) {

  weights <- c("DO"=DO, "FD"=FD, "DN"=(1-DO-FD),
               calculate_RO_parameters(b, reverse)
               )

  n_correct <- length(correct)
  n_rt <-  length(rt)
  
  if (n_correct != n_rt) {
    if (n_correct == 1) {
      correct <- rep(correct, n_rt)
    } else {
      stop("Length of 'correct' argument vector must be 1, or match length of 'rt' argument vector.")
    }
  }
  
  p <- numeric(length=n_rt)
  for (i in 1:length(p)) {
    
    if (correct[i]) {
      density_fn = dcRT
    } else {
      density_fn = deRT
    }

    x <- integrate(density_fn, 0, rt[i],
                   mu = c(mu.do, mu.g, mu.dn),
                   sigma = c(sigma, sigma, sigma),
                   nu = c(nu, nu, nu),
                   weights = weights
                   )
    p[i] <- x$value
  }

  return(p)
}


qDR <- function(p, correct, DO, FD, b, mu.do, mu.g, mu.dn, sigma, nu, reverse=FALSE) {

  DN <- 1-DO-FD
  weights <- calculate_RO_parameters(b, reverse)
  names(weights) <- c("GC_DN", "GC_FD", "GC_DO")
  
  n_samples <- 10000

  ## DO available Races
  N_DO_trials <- round(DO*n_samples)
  if (N_DO_trials > 0) {
    
    DO_RTs <- rexGAUS(N_DO_trials, mu = mu.do, sigma = sigma, nu = nu)
    guess_RTs <- rexGAUS(N_DO_trials, mu = mu.g, sigma = sigma, nu = nu)
    DO_wins <- DO_RTs <= guess_RTs
    N_DO_wins <- sum(DO_wins)
    
    if (N_DO_wins > 0) {
      
      DO_race_RTs <- ifelse(DO_wins, DO_RTs, guess_RTs)
      DO_race_correct <- numeric(N_DO_trials)
      DO_race_correct[DO_wins] <- rbinom(N_DO_wins, 1, weights["GC_DO"])
      DO_race_correct[!DO_wins] <- rbinom(N_DO_trials - N_DO_wins, 1, weights["GC_FD"])
    
    } else {
      DO_race_RTs <- guess_RTs
      DO_race_correct <- rbinom(N_DO_trials, 1, weights["GC_FD"])
    }
  } else {
    DO_race_RTs <- NULL
    DO_race_correct <- NULL
  }
  
  ## DN available Races
  N_DN_trials <- round(DN*n_samples)
  if (N_DN_trials > 0) {
    
    DN_RTs <- rexGAUS(N_DN_trials, mu = mu.dn, sigma = sigma, nu = nu)
    guess_RTs <- rexGAUS(N_DN_trials, mu = mu.g, sigma = sigma, nu = nu)
    DN_wins <- DN_RTs <= guess_RTs
    N_DN_wins <- sum(DN_wins)
    
    if (N_DN_wins > 0) {
      
      DN_race_RTs <- ifelse(DN_wins, DN_RTs, guess_RTs)
      DN_race_correct <- numeric(N_DN_trials)
      DN_race_correct[DN_wins] <- rbinom(N_DN_wins, 1, weights["GC_DN"])
      DN_race_correct[!DN_wins] <- rbinom(N_DN_trials - N_DN_wins, 1, weights["GC_FD"])
    
    } else {
      DN_race_RTs <- guess_RTs
      DN_race_correct <- rbinom(N_DN_trials, 1, weights["GC_FD"])
    }
  } else {
    DN_race_RTs <- NULL
    DN_race_correct <- NULL
  }

  ## No detection available, non-race RTs
  N_norace_trials <- n_samples - N_DN_trials - N_DO_trials
  if (N_norace_trials > 0){
    norace_RTs <- rexGAUS(N_norace_trials, mu = mu.g, sigma = sigma, nu = nu)
    norace_correct <- rbinom(N_norace_trials, 1, weights["GC_FD"])
  } else {
    norace_RTs <- NULL
    norace_correct <- NULL
  }
  

  RTs <- c(DO_race_RTs, DN_race_RTs, norace_RTs)
  accuracy <- as.logical(c(DO_race_correct, DN_race_correct, norace_correct))

  if (correct) {
    q <- quantile(RTs[accuracy], p)
  } else {
    q <- quantile(RTs[!accuracy], p)
  }
  
  return(q)
}


DR_obj <- function(theta, data) {

  data$predicted_p <- numeric(nrow(data))
  
  log_likelihood <- 0
  
  for (strength in unique(data$strength)) {

    condition_index <- data$strength==strength
    DO <- theta[paste0("DO_", strength)]
    FD <- theta[paste0("FD_", strength)]
    
    for (acc in unique(data$speeded_correct)) {

      index_vector <- condition_index & data$speeded_correct == acc
      rt_cutpoints <- data$value[index_vector]
      rt_cutpoints[length(rt_cutpoints)] <- Inf

      
      p <- pDR(rt = rt_cutpoints, correct = acc,
               DO = DO, FD = FD,
               b = theta["b"],
               mu.do = theta["mu.do"], mu.g=theta["mu.g"], mu.dn =theta["mu.dn"],
               sigma = theta["sigma"], nu=theta["nu"],
               reverse = strength == "L"
               )

      data$predicted_p[index_vector] <- diff(c(0, p))
    }

    invalid_p <- data$predicted_p[condition_index] <= 0
    if (any(invalid_p))  {
      data$predicted_p[condition_index][invalid_p] <- 1e-10
    }
    
    bin_counts <- data$bin_counts[condition_index]
    log_likelihood <- log_likelihood + dmultinom(x = bin_counts, size = sum(bin_counts),
                                                 prob = data$predicted_p[condition_index],
                                                 log = TRUE)
  }

  return(-log_likelihood)
}


twoLT <- function(theta) {
  
  RO_DN <- theta[c("RO_DN.C", "RO_DN.N", "RO_DN.L")]
  RO_FD <- theta[c("RO_FD.C", "RO_FD.N", "RO_FD.L")]
  RO_DO <- theta[c("RO_DO.C", "RO_DO.N", "RO_DO.L")]
  
  FAR <- theta["DO_L"]*RO_DO + theta["FD_L"]*RO_FD + theta["DN_L"]*RO_DN
  HR_W <- theta['DO_W']*RO_DO + theta["FD_W"]*RO_FD + theta["DN_W"]*RO_DN
  HR_S <- theta['DO_S']*RO_DO + theta["FD_S"]*RO_FD + theta["DN_S"]*RO_DN
  
  return(list(FAR=FAR, HR_W=HR_W, HR_S=HR_S))
}


twoLT_LL <- function(theta, counts, fixed=NULL) {

  preds <- twoLT(theta)

  LL <- c(dbinom(counts$H_S, size = counts$S_N, prob = preds$HR_S, log=TRUE),
          dbinom(counts$H_W, size = counts$W_N, prob = preds$HR_W, log=TRUE),
          dbinom(counts$FA, size = counts$L_N, prob = preds$FAR, log=TRUE)
          )

  return(-sum(LL))
}


twoLT_plus_DR <- function(theta, data, fixed=NULL, p_names = NULL) {

  if (!is.null(p_names)) {
    names(theta) <- p_names
  }

  if ( !("mu.dn" %in% names(theta)) ) {
    theta["mu.dn"] <- theta["mu.do"]
  }
  
  theta <- c(theta, fixed)
  theta <- parameter_scaling(theta)

  twoLT_negLL <- twoLT_LL(theta[c("DO_L", "FD_L", "DN_L",
                                  "DO_W", "FD_W", "DN_W",
                                  "DO_S", "FD_S", "DN_S",
                                  "RO_DN.C", "RO_DN.N", "RO_DN.L",
                                  "RO_FD.C", "RO_FD.N", "RO_FD.L",
                                  "RO_DO.C", "RO_DO.N", "RO_DO.L"
                                )],
                          counts = data$biased)
  
  DR_negLL <- DR_obj(theta[c("DO_L", "FD_L", "DN_L",
                             "DO_W", "FD_W", "DN_W",
                             "DO_S", "FD_S", "DN_S",
                             "b", "mu.do", "mu.g", "mu.dn", "sigma", "nu"
                             )],
                     data = data$speeded)
  
  negLL <- twoLT_negLL + DR_negLL

  return(negLL)
}
```


```{r start_cluster, dependson=c("cell_counts","discrete_race_exgaussians", "objective_functions")}
cl <- parallel::makeCluster(parallel::detectCores(),
                            outfile = "",
                            methods = FALSE)

doParallel::registerDoParallel(cl)
```

```{r data_list, dependson=c("cell_counts","discrete_race_exgaussians", "objective_functions")}
subjectwise_datalist <- Map(
  function(x,y) { list("speeded" = x,"biased" = y)},
  split(speeded_RT_choice_quantiles, speeded_RT_choice_quantiles$subject),
  split(delayed_counts_by_sub_bias, delayed_counts_by_sub_bias$subject)
  )
```

```{r fit_two_mu, dependson=c("cell_counts","discrete_race_exgaussians", "objective_functions")}

twoLT_plus_DR_fits_twoMu <- foreach(sub = subjectwise_datalist,
                                    .packages = c("optimx", "gamlss.dist")
                                    ) %dopar%
  {
    theta <- c("DO_L"=0.01, "FD_L"=0.01, "DO_W"=0.01, "FD_W"=0.01, "DO_S" = 0.01, "FD_S" = 0.01,
               "b"=0.5, "b_C" = 1, "b_N" = 0.5, "b_L" = 0,
               "mu.do" = .5, "mu.g" = .75, "sigma" = .25, "nu" = .25
               )
    fit <- optimx(theta,
                  fn = twoLT_plus_DR,
                  method = c("nmkb","nlminb"),
                  itnmax = 1000,
                  lower = c(-Inf,-Inf, -Inf, -Inf, -Inf, -Inf, -Inf, -Inf, -Inf, -Inf, 0.01, 0.01, .01, .01),
                  upper = c(Inf,  Inf,  Inf,  Inf,  Inf,  Inf,  Inf,  Inf,  Inf,  Inf, 2,    2,    .5,  .5),
                  control = list(kkt = FALSE, follow.on=TRUE),
                  data = sub,
                  p_names = names(theta)
                  )

    fit <- fit[2,]
    fit$subject <- sub$speeded$subject[1]
    fit
  }
```


```{r fit_three_mu, dependson=c("cell_counts","discrete_race_exgaussians", "objective_functions")}

twoLT_plus_DR_fits_threeMu <- foreach(sub = subjectwise_datalist,
                                      .packages = c("optimx", "gamlss.dist")
                                      ) %dopar%
  {
    theta <- c("DO_L"=0.01, "FD_L"=0.01, "DO_W"=0.01, "FD_W"=0.01, "DO_S" = 0.01, "FD_S" = 0.01,
               "b"=0.5, "b_C" = 1, "b_N" = 0.5, "b_L" = 0,
               "mu.do" = .5, "mu.g" = .75, "mu.dn" = .5, "sigma" = .25, "nu" = .25
               )
    fit <- optimx(theta,
                  fn = twoLT_plus_DR,
                  method = c("nmkb","nlminb"),
                  itnmax = 1000,
                  lower = c(-Inf,-Inf, -Inf, -Inf, -Inf, -Inf, -Inf, -Inf, -Inf, -Inf, 0.01, 0.01, 0.01, .01, .01),
                  upper = c(Inf,  Inf,  Inf,  Inf,  Inf,  Inf,  Inf,  Inf,  Inf,  Inf, 2,    2,    2,    .5,  1),
                  control = list(kkt = FALSE, follow.on=TRUE),
                  data = sub,
                  p_names = names(theta)
                  )

    fit <- fit[2,]
    fit$subject <- sub$speeded$subject[1]
    fit
  }
```

```{r combine_fits, dependson=c("fit_two_mu", "fit_three_mu")}

parameter_names <- colnames(coef(twoLT_plus_DR_fits_threeMu[[1]]))

npar <- lapply(c(twoLT_plus_DR_fits_twoMu, twoLT_plus_DR_fits_threeMu),
               attr, which="npar"
               )

twoLT_plus_DR_fits <- bind_rows("yoked" = bind_rows(twoLT_plus_DR_fits_twoMu),
                                "unyoked" = bind_rows(twoLT_plus_DR_fits_threeMu),
                                .id="model"
                                ) %>%
  mutate(nPar = unlist(npar))
```


```{r parameters, dependson=c("fit_two_mu", "fit_three_mu")}
twoLT_plus_DR_params_subject <- dplyr::select(twoLT_plus_DR_fits, subject, model, !!!parameter_names)

twoLT_plus_DR_params_scaled_subject <- rowwise(twoLT_plus_DR_params_subject) %>%
  do({
    data.frame(subject = .$subject,
               model = .$model,
               as.list(parameter_scaling(unlist(.[parameter_names]))),
               stringsAsFactors = FALSE
               )
    }) %>%
  ungroup()

twoLT_plus_DR_params_avg <- group_by(twoLT_plus_DR_params_subject, model) %>%
  summarise_at(.vars = parameter_names, "mean")
twoLT_plus_DR_params_scaled_avg <- group_by(twoLT_plus_DR_params_scaled_subject, model) %>%
  summarise_at(.vars = parameter_names, "mean")
```

```{r RT_parameters_condition_wise, dependson=c("fit_two_mu", "fit_three_mu")}
detect_params <-
  select(.data = twoLT_plus_DR_params_scaled_subject,
         subject, model, DO_L, FD_L, DN_L, DO_W, FD_W, DN_W, DO_S, FD_S, DN_S) %>%
  gather(key="param", value="value", -subject, -model) %>%
  separate(param, c("param", "strength")) %>%
  spread(param, value)

strength_wise_params <- left_join(detect_params,
                                  select(.data = twoLT_plus_DR_params_scaled_subject,
                                         subject, model, b, mu.do, mu.g, mu.dn, sigma, nu),
                                  by = c("subject", "model")
                                  )

variables <- setdiff(names(strength_wise_params), c("subject", "model", "strength"))

condition_wise_params <- bind_rows(mutate(strength_wise_params, speeded_correct = FALSE),
                                   mutate(strength_wise_params, speeded_correct = TRUE)
                                   ) %>%
  select(subject, model, strength, speeded_correct, !!!variables) %>%
  mutate(mu.dn = coalesce(mu.dn, mu.do))
```

```{r GOF, dependson="fit"}
speeded_RT_LL <- speeded_RT_choice_quantiles %>%
  group_by(subject, strength) %>%
  mutate(observed_p = bin_counts/sum(bin_counts)) %>%
  summarise(null_LL = dmultinom(bin_counts, sum(bin_counts), observed_p, log=TRUE)) %>%
  group_by(subject) %>%
  summarise(null_LL = sum(null_LL)) %>%
  ungroup()


delayed_acc_LL <- mutate(delayed_counts_by_sub_bias,
                         FA_LL = dbinom(FA, L_N, FA / L_N, log = TRUE),
                         HW_LL = dbinom(H_W, W_N, H_W / W_N, log = TRUE),
                         HS_LL = dbinom(H_S, S_N, H_S / S_N, log = TRUE),
                         LL = FA_LL + HW_LL + HS_LL) %>% 
  select(subject, pOld, LL) %>%
  group_by(subject) %>%
  summarise(null_LL = sum(LL)) %>%
  ungroup()


null_LL <- left_join(speeded_RT_LL, delayed_acc_LL,
                     by="subject", suffix=c(".RT",".acc")) %>%
  transmute(subject,
            null_LL = null_LL.RT + null_LL.acc)


twoLT_plus_DR_GOF_subject <-
  dplyr::select(.data=twoLT_plus_DR_fits,
                subject, model, value, nPar, fevals, gevals, niter, convcode) %>%
  mutate(LL = -value) %>%
  left_join(x = .,  y = null_LL,
            by = "subject") %>%
  mutate(G2 = -2*(LL - null_LL),
         df = 42 - nPar,
         p = pchisq(G2, df = df, lower.tail = FALSE)
         ) %>%
  dplyr::select(subject, model, LL, G2, df, p, fevals, gevals, niter, convcode)


twoLT_plus_DR_GOF_sum <- group_by(twoLT_plus_DR_GOF_subject, model) %>%
  summarise_at(.vars=c("LL",  "G2", "df"), "sum")
```

```{r twoLT_predictions, dependson="parameters"}
twoLT_point_predictions <-
  select(.data = twoLT_plus_DR_params_scaled_subject,
         subject, model, DO_L, FD_L, DN_L, DO_W, FD_W, DN_W, DO_S, FD_S, DN_S,
         ends_with(".C"), ends_with(".N"), ends_with(".L")) %>%
  gather(key="parameter", value="value", -subject, -model) %>%
  arrange(subject) %>%
  group_by(subject, model) %>%
  summarise(x = list(as.data.frame(
      c(pOld = list(c("25%", "50%", "75%")),
        twoLT(setNames(value, parameter))
        ),
      stringsAsFactors=FALSE
    ))) %>% 
  unnest() %>%
  rename(S=HR_S, W=HR_W) %>%
  gather(key = "strength", value="HR", S, W) %>%
  ungroup()

ROC_point_predictions <- bind_rows(mutate(obs_ROC_data, model="obs"),
                                   twoLT_point_predictions
                                   ) %>%
  select(subject, type=model, strength, pOld, FAR, HR) %>%
  arrange(subject, type, strength, pOld, type)

ROC_point_predictions_avg <- 
  group_by(.data = ROC_point_predictions, type, strength, pOld) %>%
  summarise_at(.vars = c("FAR", "HR"), .funs = "mean") %>%
  ungroup()
```

```{r speeded_accuracy, dependson="RT_parameters_condition_wise"}

predicted_probabilities <- left_join(condition_wise_params,
                                     select(speeded_RT_choice_quantiles, -bin_counts),
                                     by = c("subject", "strength", "speeded_correct")
                                     ) %>%
  rowwise() %>%
  mutate(predicted_p = pDR(rt=value, correct=speeded_correct,
                           DO, FD, b, mu.do, mu.g, mu.dn, sigma, nu,
                           reverse = strength == "L")
         ) %>%
  ungroup() %>%
  select(-variables) %>%
  group_by(subject, model, strength, speeded_correct) %>%
  mutate(predicted_p = diff(c(0, predicted_p))) %>%
  ungroup()

predicted_acc <- filter(predicted_probabilities, speeded_correct) %>%
  group_by(subject, model, strength) %>%
  summarise(predicted_acc = sum(predicted_p)) %>%
  ungroup()

accuracy <- bind_rows(rename(predicted_acc, acc = predicted_acc),
                      mutate(speeded_acc, model="obs")
                      ) %>%
  rename(type = model) %>%
  mutate(strength = factor(strength, levels = c("L","W","S")))
```

```{r speeded_quantiles, dependson="RT_parameters_condition_wise"}
predicted_quantiles <-
  foreach(r = iter(condition_wise_params, by="row"),
          .combine = bind_rows,
          .packages = "gamlss.dist"
          ) %dopar% 
  {
    r$predicted_q <- list(as.data.frame(as.list(
        qDR(p=c(.1, .3, .5, .7, .9, 1),
            correct = r$speeded_correct,
            r$DO, r$FD, r$b, r$mu.do, r$mu.g, r$mu.dn, r$sigma, r$nu,
            reverse = r$strength == "L"
            )
        ),
        check.names=FALSE))
    return(r)
  } %>%
  select(subject, model, strength, speeded_correct, predicted_q) %>%
  unnest() %>%
  gather(key="quantile", value="value", contains("%"), factor_key = TRUE) %>%
  arrange(subject, model, strength, speeded_correct)

quantiles <- bind_rows(predicted_quantiles,
                       mutate(select(speeded_RT_choice_quantiles, -bin_counts),
                              quantile = factor(quantile),
                              model = "obs"
                              )
                       ) %>%
  rename(type = model) %>%
  mutate(strength = factor(strength, levels = c("L","W","S")))

conditional_quantiles_subject <-
  mutate(accuracy, inc=1-acc) %>%
  gather(key="speeded_correct", value="p", acc, inc) %>%
  mutate(speeded_correct = ifelse(speeded_correct=="acc", TRUE, FALSE)) %>%
  right_join(quantiles,
             by = c("subject", "type", "strength", "speeded_correct")
             ) %>%
  filter(quantile != "100%") %>%
  mutate(p = p * as.numeric(sub("%", "", quantile, fixed = TRUE))/100) %>%
  rename(RT = value)

conditional_quantiles_avg <-
  group_by(.data = conditional_quantiles_subject,
           type, strength, speeded_correct, quantile
           ) %>%
  summarise_at(c("RT","p"), mean) %>%
  ungroup()
```


```{r stop_cluster}
parallel::stopCluster(cl)
```


```{r save_outputs, eval=isTRUE(getOption('knitr.in.progress'))}
files_dir <- paste0(tools::file_path_sans_ext(knitr::current_input()),
                    "_files"
                    )
if (!dir.exists(files_dir)) {
  dir.create(files_dir)
}

write.csv(twoLT_plus_DR_params_subject,
          file = file.path(files_dir, "parameters.csv"),
          row.names = FALSE
          )
write.csv(twoLT_plus_DR_params_scaled_subject,
          file = file.path(files_dir, "scaled_parameters.csv"),
          row.names = FALSE
          )
write.csv(twoLT_plus_DR_GOF_subject,
          file = file.path(files_dir, "GOF.csv"),
          row.names = FALSE
          )
```

```{r avg_ROC_plot, fig.width=7, fig.height=7, dependson="twoLT_predictions"}
ggplot(ROC_point_predictions_avg,
       aes(x=FAR, y=HR,  shape=type, linetype=strength,
           group=interaction(type, strength))
       ) +
  geom_line(size=1) +
  geom_point(aes(color=pOld), size=2, stroke=1.3) +
  scale_x_continuous("False Alarm Rate", limits = c(0,1),
                     labels = c(0,0.25, 0.5, 0.75, 1)) +
  scale_y_continuous("Hit Rate", limits = c(0,1)) +
  scale_linetype_discrete("Strength",
                          labels=c("W" = "Weak",
                                   "S" = "Strong")) +
  scale_color_manual("p(Old)", values = c("#d82d2d", "#d8d834", "#17b50c")) +
  scale_shape_manual("Type",
                     values=c(16, 15, 4),
                     breaks = c("obs", "yoked", "unyoked"),
                     labels = c("Observed", "Two Mu's", "Three Mu's")
                     ) +
  guides(colour = guide_legend(override.aes = list(size = 4)),
         shape = guide_legend(override.aes = list(size = 4))) +
  ggtitle("Two LT Model ROC") +
  theme_bw(base_size = 16) +
  theme(plot.title = element_text(hjust=.5),
        strip.background = element_blank(),
        legend.key.width = unit(10,"mm"),
        legend.position = c(.6, .15),
        legend.box = "horizontal")
```


```{r QP_plot, fig.width=10, fig.height=7, dependson=c("speeded_quantiles","speeded_accuracy")}
ggplot(conditional_quantiles_avg,
       aes(x=RT, y=p, color=speeded_correct, linetype=type, shape=type)) +
  geom_point(size=2) +
  geom_line(size=1) +
  facet_grid(~strength,
             labeller = as_labeller(c("L" = "Lure", "W" = "Weak", "S" = "Strong"))
             ) +
  scale_color_manual("Accuracy",
                     values = RColorBrewer::brewer.pal(3, 'Set1')[1:2],
                     limits=c("FALSE","TRUE"),
                     labels=c("Incorrect", "Correct")) +
  scale_linetype_manual(NULL,
                        values = c(5, 2, 1),
                        limits = c("unyoked", "yoked", "obs"),
                        labels = c("yoked" = "Two Mu's",
                                   "unyoked" = "Three Mu's",
                                   "obs" = "Observed")
                        ) +
  scale_shape_manual(NULL,
                     values = c(17, 15, 16),
                     limits = c("unyoked", "yoked", "obs"),
                     labels = c("yoked" = "Two Mu's",
                                "unyoked" = "Three Mu's",
                                "obs" = "Observed")
                     ) +
  guides(color = guide_legend(order = 1)) +
  ggtitle("2LT + Discrete Race",
          subtitle="Conditional Quantiles (Average)") +
  scale_x_continuous("Response Time (s.)") +
  theme_bw(base_size=16) +
  theme(plot.title = element_text(hjust=.5),
        plot.subtitle = element_text(hjust=.5),
        strip.background = element_blank(),
        legend.key.width = unit(2,"line")
        )
```

```{r param_summary_tables, dependson="parameters"}
formatted_names_map <- c(subject="Subject", model="model", DO_L="DO<sub>L</sub>", FD_L="FD<sub>L</sub>", 
                         DO_W="DO<sub>W</sub>", FD_W="FD<sub>W</sub>", DO_S="DO<sub>S</sub>",
                         FD_S="FD<sub>S</sub>", b="b", b_C="b<sub>C</sub>", b_N="b<sub>N</sub>",
                         b_L="b<sub>L</sub>", mu.do="μ<sub>D</sub>", mu.g="μ<sub>G</sub>",
                         mu.dn = "μ<sub>DN</sub>", sigma="\U03C3", nu="v", G2="G<sup>2</sup>",
                         LL="LL", null_LL="Null LL",  df="df", p="p(X<sup>2</sup>)",
                         fevals="fevals", gevals="gevals", niter="niter", convcode="convcode"
                         )


left_join(select(twoLT_plus_DR_params_scaled_subject, -starts_with("RO"), -starts_with("DN")),
          select(twoLT_plus_DR_GOF_subject, subject, model, G2),
          by=c("subject", "model")
          ) %>%
  select(model, subject, !!!parameter_names, G2) %>%
  kable(digits=3,
        col.names = formatted_names_map[names(.)],
        escape=FALSE,
        ) %>%
  kableExtra::kable_styling(full_width = FALSE) %>%
  kableExtra::column_spec(1:2, bold=TRUE) %>%
  kableExtra::collapse_rows(1)
```

```{r download_links, results="asis"}
cat("<ul><li>",
    paste0('<a  href="', file.path(files_dir, "scaled_parameters.csv"),
           '">Download Scaled Parameters</a>'
           ),
    "</li><li>",
    paste0('<a href="', file.path(files_dir, "parameters.csv"),
           '">Download Raw Parameters</a>'
           ),
    "</li><li>",
    paste0('<a href="',
           file.path(files_dir, "GOF.csv"),
           '">Download GOF Statistics</a>'
       ),
    "</li></ul>",
    sep=""
    )
```


## Individual Subjects
```{r subject_ROC_plots, fig.width=10, fig.height=10, dependson="2LT_predictions"}
ggplot(ROC_point_predictions,
       aes(x=FAR, y=HR,  shape=type, linetype=strength,
           group=interaction(type, strength))
       ) +
  geom_line(size=1) +
  geom_point(aes(color=pOld), size=2, stroke=1.3) +
  facet_wrap(~subject, labeller = label_both) +
  scale_x_continuous("False Alarm Rate", limits = c(0,1),
                     labels = c(0,0.25, 0.5, 0.75, 1)) +
  scale_y_continuous("Hit Rate", limits = c(0,1)) +
  scale_linetype_discrete("Strength",
                          labels=c("W" = "Weak",
                                   "S" = "Strong")) +
  scale_color_manual("p(Old)", values = c("#d82d2d", "#d8d834", "#17b50c")) +
  scale_shape_manual("Type",
                     values=c(16, 15, 4),
                     breaks = c("obs", "yoked", "unyoked"),
                     labels = c("Observed", "Two Mu's", "Three Mu's")
                     ) +
  guides(colour = guide_legend(override.aes = list(size = 4)),
         shape = guide_legend(override.aes = list(size = 4))) +
  ggtitle("Two LT Model ROC") +
  theme_bw(base_size = 16) +
  theme(plot.title = element_text(hjust=.5),
        strip.background = element_blank(),
        legend.key.width = unit(10,"mm"),
        legend.position = c(.75, .10),
        legend.box = "horizontal")
```


```{r subject_RT_plots, class.output="subject_speeded_RT", fig.width=10, fig.align="center", results="asis", dependson=c("parameters","GOF", "twoLT_predictions", "speeded_accuracy", "speeded_quantiles"),}

for (s in unique(speeded_RT_choice_quantiles$subject)) {
  
  cat(sprintf("<h3>Subject %s</h3>", s))
  
  subject_params <- filter(twoLT_plus_DR_params_scaled_subject, subject == s) %>%
    select(-subject, -starts_with("RO"), -starts_with("DN"))
  subject_GOF <- filter(twoLT_plus_DR_GOF_subject, subject == s)[,-1]

  kable(subject_params,
        digits=3, escape = FALSE,
        row.names=FALSE,
        col.names = formatted_names_map[colnames(subject_params)],
        ) %>%
    kableExtra::kable_styling(full_width = FALSE, position = "float_left") %>%
    kableExtra::column_spec(1, bold=TRUE) %>%
    print()
  
    kable(subject_GOF,
          digits = 3, escape = FALSE,
          row.names=FALSE,
          col.names = formatted_names_map[colnames(subject_GOF)],
          ) %>%
    kableExtra::kable_styling(full_width = FALSE, position = "float_left") %>%
    kableExtra::column_spec(1, bold=TRUE) %>%
    print()

  acc_plot <-
    ggplot(filter(accuracy, subject == s),
          aes(x=strength, y=acc, shape=type, color=strength)
          ) +
    geom_point(size=2, stroke=2,
               position = position_dodge(width=.35)
               ) +
    scale_shape_manual(NULL,
                       values=c(16, 15, 4),
                       breaks = c("obs", "yoked", "unyoked"),
                       labels = c("Observed", "Two Mu's", "Three Mu's")
                       ) +
    scale_color_discrete("Strength",
                         limits = c("L", "W", "S"),
                         labels = c("L" = "Lure",
                                    "W" = "Weak\nTarget",
                                    "S" = "Strong\nTarget")
                         ) +
    scale_y_continuous("Percent Correct", limits = c(0, 1)) +
    scale_x_discrete("",
                     labels = c("", "", ""),
                     limits = c("L","W","S"),
                     expand = c(0, .2)
                     ) +
    theme(legend.key.height = unit(9, 'mm'),
          axis.title.x = element_blank(),
          axis.ticks.x = element_blank(),
          axis.text.x = element_blank()
          )
  
  quantile_plot <- 
    ggplot(filter(quantiles, subject == s, quantile != "100%"),
           aes(x=quantile, y=value, shape=type, color=strength)) +
    geom_point(size=1.5) +
    geom_line(aes(group=type)) +
    facet_grid(speeded_correct ~ strength,
               labeller = labeller(speeded_correct = as_labeller(
                                    c("TRUE" = "Correct",
                                      "FALSE" = "Error")
                                    ),
                                    strength = as_labeller(
                                      c("L" = "Lure",
                                        "S" = "Strong Target",
                                        "W" = "Weak Target")
                                    )
                                   )
               ) +
    scale_shape_manual(NULL,
                       values=c(16, 15, 4),
                       breaks = c("obs", "yoked", "unyoked"),
                       labels = c("Observed", "Two Mu's", "Three Mu's")
                       ) +
    scale_color_discrete("Strength",
                         limits = c("L", "W", "S"),
                         labels = c("L" = "Lure",
                                    "W" = "Weak\nTarget",
                                    "S" = "Strong\nTarget")
                         ) +
    scale_y_continuous("RT Quantile Value (s.)") +
    guides(color=FALSE, shape=FALSE)
  
  gridExtra::grid.arrange(acc_plot, quantile_plot, nrow=1,
                          widths=c(.27, .73)
                          )
}
```
